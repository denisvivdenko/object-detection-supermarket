{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CSV columns are: image_name,x1,y1,x2,y2,class,image_width,image_height\n",
    "columns = [\"image_name\", \"x1\", \"y1\", \"x2\", \"y2\", \"class_name\", \"image_width\", \"image_height\"]\n",
    "\n",
    "train_annotations = pd.read_csv('../data/SKU110K_fixed/annotations/annotations_train.csv', header=None)\n",
    "train_annotations.columns = columns\n",
    "\n",
    "test_annotations = pd.read_csv('../data/SKU110K_fixed/annotations/annotations_test.csv', header=None)\n",
    "test_annotations.columns = columns\n",
    "\n",
    "val_annotations = pd.read_csv('../data/SKU110K_fixed/annotations/annotations_val.csv', header=None)\n",
    "val_annotations.columns = columns\n",
    "\n",
    "dataset = {\n",
    "    \"train\": train_annotations,\n",
    "    \"test\": test_annotations,\n",
    "    \"val\": val_annotations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>class_name</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>208</td>\n",
       "      <td>537</td>\n",
       "      <td>422</td>\n",
       "      <td>814</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>1268</td>\n",
       "      <td>1923</td>\n",
       "      <td>1365</td>\n",
       "      <td>2209</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>1135</td>\n",
       "      <td>2074</td>\n",
       "      <td>1261</td>\n",
       "      <td>2166</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>1045</td>\n",
       "      <td>2085</td>\n",
       "      <td>1122</td>\n",
       "      <td>2258</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>976</td>\n",
       "      <td>2036</td>\n",
       "      <td>1040</td>\n",
       "      <td>2177</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_name    x1    y1    x2    y2 class_name  image_width  image_height\n",
       "0  train_0.jpg   208   537   422   814     object         3024          3024\n",
       "1  train_0.jpg  1268  1923  1365  2209     object         3024          3024\n",
       "2  train_0.jpg  1135  2074  1261  2166     object         3024          3024\n",
       "3  train_0.jpg  1045  2085  1122  2258     object         3024          3024\n",
       "4  train_0.jpg   976  2036  1040  2177     object         3024          3024"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([        655,         118,       60867,       79487,  2.4075e+05,  5.3149e+05,       19014,   2.552e+05,       14472,        6432]),\n",
       " array([        640,      1107.2,      1574.4,      2041.6,      2508.8,        2976,      3443.2,      3910.4,      4377.6,      4844.8,        5312]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_annotations.image_width)\n",
    "plt.hist(train_annotations.image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1208482 entries, 0 to 1208481\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count    Dtype \n",
      "---  ------        --------------    ----- \n",
      " 0   image_name    1208482 non-null  object\n",
      " 1   x1            1208482 non-null  int64 \n",
      " 2   y1            1208482 non-null  int64 \n",
      " 3   x2            1208482 non-null  int64 \n",
      " 4   y2            1208482 non-null  int64 \n",
      " 5   class_name    1208482 non-null  object\n",
      " 6   image_width   1208482 non-null  int64 \n",
      " 7   image_height  1208482 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 73.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_annotations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/denys/object-detection-supermarket/notebooks/../data/examples/001.jpg: 448x640 (no detections), 83.7ms\n",
      "Speed: 4.1ms preprocess, 83.7ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(f'../models/yolov8n.pt')\n",
    "results = model.predict(source='../data/examples/001.jpg', conf=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "boxes: tensor([], size=(0, 6))\n",
       "cls: tensor([])\n",
       "conf: tensor([])\n",
       "data: tensor([], size=(0, 6))\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (2396, 3594)\n",
       "shape: torch.Size([0, 6])\n",
       "xywh: tensor([], size=(0, 4))\n",
       "xywhn: tensor([], size=(0, 4))\n",
       "xyxy: tensor([], size=(0, 4))\n",
       "xyxyn: tensor([], size=(0, 4))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>class_name</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>208</td>\n",
       "      <td>537</td>\n",
       "      <td>422</td>\n",
       "      <td>814</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>1268</td>\n",
       "      <td>1923</td>\n",
       "      <td>1365</td>\n",
       "      <td>2209</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>1135</td>\n",
       "      <td>2074</td>\n",
       "      <td>1261</td>\n",
       "      <td>2166</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>1045</td>\n",
       "      <td>2085</td>\n",
       "      <td>1122</td>\n",
       "      <td>2258</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>976</td>\n",
       "      <td>2036</td>\n",
       "      <td>1040</td>\n",
       "      <td>2177</td>\n",
       "      <td>object</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_name    x1    y1    x2    y2 class_name  image_width  image_height\n",
       "0  train_0.jpg   208   537   422   814     object         3024          3024\n",
       "1  train_0.jpg  1268  1923  1365  2209     object         3024          3024\n",
       "2  train_0.jpg  1135  2074  1261  2166     object         3024          3024\n",
       "3  train_0.jpg  1045  2085  1122  2258     object         3024          3024\n",
       "4  train_0.jpg   976  2036  1040  2177     object         3024          3024"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13317"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_annotations[\"x2\"] > train_annotations[\"image_width\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = {class_name: i for i, class_name in enumerate(pd.concat([d for d in dataset.values()])[\"class_name\"].unique())}\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 193\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError processing image: \u001b[39m\u001b[39m{\u001b[39;00mimage_metadata[\u001b[39m'\u001b[39m\u001b[39mimage_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    191\u001b[0m                 \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m prepare_dataset(params, dataset, \u001b[39m\"\u001b[39m\u001b[39m../data/dataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m../data/SKU110K_fixed/images\u001b[39m\u001b[39m\"\u001b[39m, max_batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "import random\n",
    "from src.utils.load_params import load_params\n",
    "\n",
    "params = load_params(\"../params.yaml\")\n",
    "\n",
    "def clear_directory(path: str) -> None:\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)  # Remove files and symbolic links\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)  # Remove subdirectories\n",
    "\n",
    "\n",
    "def get_augmentations() -> A.ReplayCompose:\n",
    "    return A.ReplayCompose([\n",
    "        A.OneOf([\n",
    "            A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.9),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.9),\n",
    "        ], p=0.9),\n",
    "        A.ToGray(p=0.01),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.1),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Transpose(p=0.1),\n",
    "        A.ImageCompression(quality_lower=85, quality_upper=95, p=0.2),\n",
    "        A.OneOf([\n",
    "            A.Blur(blur_limit=3, p=1.0),\n",
    "            A.MedianBlur(blur_limit=3, p=1.0)\n",
    "        ], p=0.1),\n",
    "        A.Resize(height=416, width=416, p=1),\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['labels'], min_visibility=0.1), p=1)\n",
    "\n",
    "\n",
    "def convert_boxes_to_yolo_format(x1: int, y1: int, x2: int, y2: int, image_width: int, image_height: int) -> str:\n",
    "    \"\"\"\n",
    "        Converts the bounding box coordinates to yolo format\n",
    "\n",
    "        returns: str \"x_center_n y_center_n bbox_width_n bbox_height_n\"\n",
    "    \"\"\"\n",
    "\n",
    "    x2 = min(x2, image_width)\n",
    "    y2 = min(y2, image_height)\n",
    "\n",
    "    x_center = (x1 + x2) / 2\n",
    "    y_center = (y1 + y2) / 2\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "    \n",
    "\n",
    "    # if x2 > image_width or y2 > image_height:\n",
    "\n",
    "    #     print(f\"Out of bound box: {x1, y1, x2, y2} for image of size: {image_width, image_height}\")\n",
    "\n",
    "    # if x1 > x2 or y1 > y2:\n",
    "    #     raise ValueError(\"x1 > x2 or y1 > y2\")\n",
    "\n",
    "    x_center_n = x_center / image_width\n",
    "    y_center_n = y_center / image_height\n",
    "    width_n = width / image_width\n",
    "    height_n = height / image_height\n",
    "\n",
    "    x_center_n = min(max(x_center_n, 0), 1)\n",
    "    y_center_n = min(max(y_center_n, 0), 1)\n",
    "    width_n = min(max(width_n, 0), 1)\n",
    "    height_n = min(max(height_n, 0), 1)\n",
    "    \n",
    "    return {\n",
    "        \"x_center_n\": x_center_n,\n",
    "        \"y_center_n\": y_center_n,\n",
    "        \"width_n\": width_n,\n",
    "        \"height_n\": height_n\n",
    "    } \n",
    "\n",
    "\n",
    "def process_image(image_metadata: pd.DataFrame, split: str, images_dir: str, data_dir: str, classes_dict: dict):\n",
    "    image_name =  image_metadata[\"image_name\"].values[0]\n",
    "    image_fpath = images_dir / image_name\n",
    "\n",
    "    new_image_dir = data_dir / \"images\" / split\n",
    "    new_label_dir = data_dir / \"labels\" / split\n",
    "\n",
    "    \n",
    "    image = Image.open(image_fpath)\n",
    "    image = np.array(image)\n",
    "    bboxes = [convert_boxes_to_yolo_format(box.x1, box.y1, box.x2, box.y2, box.image_width, box.image_height).values() for _, box in image_metadata.iterrows()]\n",
    "    classes = [classes_dict[box[\"class_name\"]] for _, box in image_metadata.iterrows()]\n",
    "    base_random_state = params[\"base\"][\"random_state\"]\n",
    "\n",
    "    augmentations = [{\n",
    "        \"image\": image,\n",
    "        \"bboxes\": bboxes,\n",
    "        \"classes\": classes,\n",
    "        f\"fname\": f\"{image_name.split('.')[0]}_{0}\"\n",
    "    }]\n",
    "    \n",
    "    for i in range(1, params[\"yolo_preprocessing\"][\"n_augmentations\"] + 1):\n",
    "        new_seed = base_random_state + i\n",
    "        np.random.seed(new_seed)\n",
    "        random.seed(new_seed)\n",
    "        augmenter = get_augmentations()\n",
    "        augmentation = augmenter(image=image, bboxes=bboxes, labels=classes)\n",
    "        augmented_image = augmentation[\"image\"]\n",
    "        augmented_bboxes = augmentation[\"bboxes\"]\n",
    "\n",
    "        augmentations.append({\n",
    "            \"image\": augmented_image, \n",
    "            \"bboxes\": augmented_bboxes,\n",
    "            \"classes\": classes,\n",
    "            f\"fname\": f\"{image_name.split('.')[0]}_{i}\"\n",
    "        })\n",
    "        \n",
    "    np.random.seed(base_random_state)\n",
    "    random.seed(base_random_state)\n",
    "    \n",
    "    for augmented_image_metadata in augmentations:\n",
    "        augmented_image = Image.fromarray(augmented_image_metadata[\"image\"])\n",
    "        augmented_image.save(new_image_dir / f'{augmented_image_metadata[\"fname\"]}.jpg')\n",
    "\n",
    "        with open(new_label_dir / f'{augmented_image_metadata[\"fname\"]}.txt', \"a\") as f:\n",
    "            for class_name, bbox in zip(augmented_image_metadata[\"classes\"], augmented_image_metadata[\"bboxes\"]):\n",
    "                f.write(f\"{class_name} \" + ' '.join([str(v) for v in list(bbox)]) + \"\\n\")\n",
    "\n",
    "\n",
    "def prepare_dataset(\n",
    "        params, \n",
    "        datasets: pd.DataFrame, \n",
    "        data_path: str, \n",
    "        images_dir: str,\n",
    "        max_batch_size: int = None\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "        datasets: dict\n",
    "            {\n",
    "                \"train\": ...,\n",
    "                \"test\": ...,\n",
    "                \"val\": ...\n",
    "            }\n",
    "\n",
    "        Creates this data structure\n",
    "\n",
    "        dataset\n",
    "            - images\n",
    "                - train\n",
    "                    - 001.jpg\n",
    "                - test\n",
    "                    - 001.jpg\n",
    "                - val\n",
    "                    - 001.jpg\n",
    "            - labels\n",
    "                - train\n",
    "                    - 001.txt\n",
    "                - test\n",
    "                    - 001.txt\n",
    "                - val\n",
    "                    - 001.txt\n",
    "\n",
    "        YOLO expects this format x_center_n, y_center_n bbox_width_n, bbox_height_n\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_path)\n",
    "    images_dir = Path(images_dir)\n",
    "\n",
    "    if os.path.exists(data_dir):\n",
    "        shutil.rmtree(data_dir)\n",
    "    for split in datasets:\n",
    "        os.makedirs(data_dir / f\"images/{split}\", exist_ok=True)\n",
    "        os.makedirs(data_dir / f\"labels/{split}\", exist_ok=True)\n",
    "\n",
    "    classes_dict = {class_name: i for i, class_name in enumerate(pd.concat([d for d in dataset.values()])[\"class_name\"].unique())}\n",
    "    for split in datasets:\n",
    "        for i, (_, image_metadata) in enumerate(tqdm(datasets[split].groupby(\"image_name\"))):\n",
    "            if max_batch_size is not None and i > max_batch_size:\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                process_image(\n",
    "                    image_metadata=image_metadata,\n",
    "                    split=split,\n",
    "                    data_dir=data_dir,\n",
    "                    images_dir=images_dir,\n",
    "                    classes_dict=classes_dict\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image: {image_metadata['image_name'].values[0]} {e}\")\n",
    "                continue\n",
    "\n",
    "prepare_dataset(params, dataset, \"../data/dataset\", \"../data/SKU110K_fixed/images\", max_batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/denys/object-detection-supermarket/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(f\"../models/yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.167 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.166 🚀 Python-3.10.12 torch-2.0.1+cu117 CPU (11th Gen Intel Core(TM) i7-11390H 3.40GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=../models/yolov8n.pt, data=../yolo_params.yaml, epochs=1, patience=50, batch=1, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=0, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=/home/denys/object-detection-supermarket/runs/detect/train13\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/denys/object-detection-supermarket/data/dataset/labels/train.cache... 303 images, 0 backgrounds, 0 corrupt: 100%|██████████| 303/303 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/denys/object-detection-supermarket/data/dataset/labels/val.cache... 303 images, 0 backgrounds, 0 corrupt: 100%|██████████| 303/303 [00:00<?, ?it/s]\n",
      "Plotting labels to /home/denys/object-detection-supermarket/runs/detect/train13/labels.jpg... \n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/denys/object-detection-supermarket/venv/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/home/denys/object-detection-supermarket/runs/detect/train13\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/1         0G      2.159      1.743      1.376        372        640: 100%|██████████| 303/303 [01:14<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 152/152 [00:42<00:00,  3.55it/s]\n",
      "                   all        303      45099      0.627      0.528      0.578      0.279\n",
      "\n",
      "1 epochs completed in 0.033 hours.\n",
      "Optimizer stripped from /home/denys/object-detection-supermarket/runs/detect/train13/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /home/denys/object-detection-supermarket/runs/detect/train13/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /home/denys/object-detection-supermarket/runs/detect/train13/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.166 🚀 Python-3.10.12 torch-2.0.1+cu117 CPU (11th Gen Intel Core(TM) i7-11390H 3.40GHz)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 152/152 [00:27<00:00,  5.50it/s]\n",
      "                   all        303      45099      0.627      0.527      0.578      0.279\n",
      "Speed: 1.0ms preprocess, 51.3ms inference, 0.0ms loss, 8.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/denys/object-detection-supermarket/runs/detect/train13\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f39bf8fe290>\n",
       "fitness: 0.3087518799960556\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.27881])\n",
       "names: {0: 'object'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.626674049967859, 'metrics/recall(B)': 0.5271513780793365, 'metrics/mAP50(B)': 0.5782085941388051, 'metrics/mAP50-95(B)': 0.27881224509130564, 'fitness': 0.3087518799960556}\n",
       "save_dir: PosixPath('/home/denys/object-detection-supermarket/runs/detect/train13')\n",
       "speed: {'preprocess': 1.0133135830215103, 'inference': 51.34222688454606, 'loss': 0.0011645527956115924, 'postprocess': 8.352389036625526}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(\n",
    "    data=\"../yolo_params.yaml\",\n",
    "    epochs=1,\n",
    "    batch=1,\n",
    "    save_dir=\"../models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/denys/object-detection-supermarket/notebooks/../data/examples/001.jpg: 448x640 161 objects, 68.0ms\n",
      "Speed: 2.2ms preprocess, 68.0ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(source=\"../data/examples/001.jpg\", conf=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res[0].plot(line_width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res[:, :, ::-1]\n",
    "res = Image.fromarray(res)\n",
    "res.save(\"../data/examples/001_pred.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
